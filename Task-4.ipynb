{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClimateScope Dashboard - Interactive Climate Analysis\n",
    "\n",
    "This notebook contains the complete ClimateScope dashboard application for analyzing climate and weather data.\n",
    "\n",
    "**Note:** This is a Streamlit application. To run it:\n",
    "- Install Streamlit: `pip install streamlit`\n",
    "- Run: `streamlit run app.py`\n",
    "\n",
    "Alternatively, you can use `streamlit-in-notebook` to run Streamlit apps within Jupyter notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- CONFIG & SETUP -------------------------\n",
    "st.set_page_config(\n",
    "    page_title=\"ClimateScope Dashboard\",\n",
    "    page_icon=\"üåç\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Theme & Color Scheme Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- THEME & COLOR SCHEME -------------------------\n",
    "# Consistent color palette for all visualizations\n",
    "COLOR_SCHEME = {\n",
    "    'primary': '#1f77b4',\n",
    "    'secondary': '#ff7f0e',\n",
    "    'accent': '#2ca02c',\n",
    "    'warning': '#d62728',\n",
    "    'info': '#9467bd',\n",
    "    'success': '#8c564b',\n",
    "    'season_winter': '#4A90E2',\n",
    "    'season_spring': '#50C878',\n",
    "    'season_summer': '#FF6B35',\n",
    "    'season_fall': '#D2691E',\n",
    "    'gradient': ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f']\n",
    "}\n",
    "\n",
    "SEASON_COLORS = {\n",
    "    'Winter': COLOR_SCHEME['season_winter'],\n",
    "    'Spring': COLOR_SCHEME['season_spring'],\n",
    "    'Summer': COLOR_SCHEME['season_summer'],\n",
    "    'Fall': COLOR_SCHEME['season_fall']\n",
    "}\n",
    "\n",
    "# Plotly color scales for consistency\n",
    "PLOTLY_COLORSCALE = \"Viridis\"\n",
    "PLOTLY_CORR_COLORSCALE = \"RdBu_r\"\n",
    "\n",
    "# Chart template\n",
    "CHART_TEMPLATE = {\n",
    "    'layout': go.Layout(\n",
    "        font=dict(family=\"Arial, sans-serif\", size=12, color=\"#333\"),\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        xaxis=dict(showgrid=True, gridcolor='rgba(128,128,128,0.2)'),\n",
    "        yaxis=dict(showgrid=True, gridcolor='rgba(128,128,128,0.2)'),\n",
    "        hovermode='closest',\n",
    "        legend=dict(bgcolor='rgba(255,255,255,0.8)', bordercolor='rgba(0,0,0,0.2)', borderwidth=1)\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 07:01:01.358 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- DATA LOADING & PROCESSING -------------------------\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    try:\n",
    "        df = pd.read_csv(\"cleaned_weather_data.csv\", parse_dates=[\"date\", \"last_updated\"])\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Data file 'cleaned_weather_data.csv' not found. Please ensure the file is in the directory.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- Data Cleaning & Feature Engineering ---\n",
    "    cols_to_numeric = ['temperature_celsius', 'humidity', 'precip_mm', 'wind_kph', 'pressure_mb', 'uv_index']\n",
    "    for col in cols_to_numeric:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    df[\"month_name\"] = df[\"date\"].dt.month_name()\n",
    "    df[\"month_num\"] = df[\"date\"].dt.month\n",
    "    df[\"year\"] = df[\"date\"].dt.year\n",
    "    \n",
    "    def get_season(m):\n",
    "        if m in [12, 1, 2]: return \"Winter\"\n",
    "        elif m in [3, 4, 5]: return \"Spring\"\n",
    "        elif m in [6, 7, 8]: return \"Summer\"\n",
    "        else: return \"Fall\"\n",
    "    df[\"season\"] = df[\"month_num\"].apply(get_season)\n",
    "\n",
    "    # Heat Index & Wind Chill (Approx)\n",
    "    df[\"heat_index_c\"] = df[\"temperature_celsius\"] + (df[\"humidity\"] / 100) * (df[\"temperature_celsius\"] - 15)\n",
    "    T = df[\"temperature_celsius\"]\n",
    "    V = df[\"wind_kph\"]\n",
    "    df[\"wind_chill_c\"] = np.where(\n",
    "        (T <= 10) & (V >= 4.8),\n",
    "        13.12 + 0.6215*T - 11.37*(V**0.16) + 0.3965*T*(V**0.16),\n",
    "        T\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 07:01:02.205 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-12-30 07:01:02.225 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "df_raw = load_data()\n",
    "\n",
    "if df_raw.empty:\n",
    "    st.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sidebar Navigation and Filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- SIDEBAR NAVIGATION & FILTERS -------------------------\n",
    "\n",
    "st.sidebar.title(\"üåç ClimateScope\")\n",
    "\n",
    "# Navigation\n",
    "nav_selection = st.sidebar.radio(\n",
    "    \"Navigation\", \n",
    "    [\"Executive Dashboard\", \"Statistical Analysis\", \"Climate Trends\", \"Extreme Events\", \"Help & User Guide\"]\n",
    ")\n",
    "\n",
    "st.sidebar.markdown(\"---\")\n",
    "st.sidebar.header(\"Global Filters\")\n",
    "\n",
    "# --- 1. COUNTRY FILTER (CLEAN UI) ---\n",
    "all_countries = sorted(df_raw[\"country\"].dropna().unique())\n",
    "\n",
    "# \"Select All\" Toggle to avoid the messy tag cloud\n",
    "select_all_countries = st.sidebar.checkbox(\"Select All Countries\", value=True)\n",
    "\n",
    "if select_all_countries:\n",
    "    selected_countries = all_countries\n",
    "else:\n",
    "    # If unchecked, allow specific selection (starts empty for cleanliness)\n",
    "    selected_countries = st.sidebar.multiselect(\n",
    "        \"Select Specific Countries\", \n",
    "        options=all_countries, \n",
    "        default=[] \n",
    "    )\n",
    "    if not selected_countries:\n",
    "        st.sidebar.warning(\"‚ö†Ô∏è Please select at least one country.\")\n",
    "\n",
    "# --- 2. DATE RANGE FILTER ---\n",
    "min_date = df_raw[\"date\"].min().date()\n",
    "max_date = df_raw[\"date\"].max().date()\n",
    "date_range = st.sidebar.date_input(\"Date Range\", [min_date, max_date], min_value=min_date, max_value=max_date)\n",
    "\n",
    "# --- 3. LOCATION FILTER (NEW) ---\n",
    "st.sidebar.markdown(\"### Location Filter\")\n",
    "all_locations = sorted(df_raw[\"location_name\"].dropna().unique())\n",
    "select_all_locations = st.sidebar.checkbox(\"Select All Locations\", value=True, key=\"loc_all\")\n",
    "\n",
    "if select_all_locations:\n",
    "    selected_locations = all_locations\n",
    "else:\n",
    "    selected_locations = st.sidebar.multiselect(\n",
    "        \"Select Specific Locations\", \n",
    "        options=all_locations, \n",
    "        default=[],\n",
    "        key=\"loc_select\"\n",
    "    )\n",
    "\n",
    "# --- 4. METRIC SELECTOR ---\n",
    "st.sidebar.markdown(\"### Metric Selection\")\n",
    "metric_options = {\n",
    "    \"Temperature (¬∞C)\": \"temperature_celsius\",\n",
    "    \"Precipitation (mm)\": \"precip_mm\",\n",
    "    \"Wind Speed (kph)\": \"wind_kph\",\n",
    "    \"Humidity (%)\": \"humidity\",\n",
    "    \"Pressure (mb)\": \"pressure_mb\",\n",
    "    \"UV Index\": \"uv_index\",\n",
    "    \"Heat Index (¬∞C)\": \"heat_index_c\",\n",
    "    \"Wind Chill (¬∞C)\": \"wind_chill_c\"\n",
    "}\n",
    "selected_metric_label = st.sidebar.selectbox(\"Primary Metric\", list(metric_options.keys()))\n",
    "selected_metric = metric_options[selected_metric_label]\n",
    "\n",
    "# --- 5. ADVANCED FILTERS (NEW) ---\n",
    "st.sidebar.markdown(\"### Advanced Controls\")\n",
    "with st.sidebar.expander(\"üìä Visualization Settings\", expanded=False):\n",
    "    moving_avg_window = st.slider(\"Moving Average Window (days)\", min_value=1, max_value=30, value=7, step=1)\n",
    "    show_trend_line = st.checkbox(\"Show Trend Line\", value=True)\n",
    "    show_confidence_band = st.checkbox(\"Show Confidence Band\", value=False)\n",
    "    \n",
    "with st.sidebar.expander(\"üìà Threshold Settings\", expanded=False):\n",
    "    percentile_threshold = st.slider(\"Percentile Threshold for Anomalies\", min_value=90, max_value=99, value=95, step=1)\n",
    "    enable_anomaly_detection = st.checkbox(\"Highlight Anomalies\", value=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Filtering Logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Testing Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 07:01:03.904 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- TESTING MODULE -------------------------\n",
    "# Comprehensive testing for functionality, data accuracy, and user experience\n",
    "\n",
    "def run_data_validation_tests(df):\n",
    "    \"\"\"Test data accuracy and integrity\"\"\"\n",
    "    tests = {\n",
    "        \"Data Loaded\": not df.empty,\n",
    "        \"Required Columns Present\": all(col in df.columns for col in [\n",
    "            \"date\", \"country\", \"location_name\", \"temperature_celsius\", \n",
    "            \"precip_mm\", \"wind_kph\", \"humidity\", \"pressure_mb\"\n",
    "        ]),\n",
    "        \"Date Column Valid\": pd.api.types.is_datetime64_any_dtype(df[\"date\"]),\n",
    "        \"No Negative Temperatures (Extreme)\": (df[\"temperature_celsius\"] > -50).all() if \"temperature_celsius\" in df.columns else True,\n",
    "        \"No Negative Precipitation\": (df[\"precip_mm\"] >= 0).all() if \"precip_mm\" in df.columns else True,\n",
    "        \"Humidity in Valid Range\": ((df[\"humidity\"] >= 0) & (df[\"humidity\"] <= 100)).all() if \"humidity\" in df.columns else True,\n",
    "        \"Wind Speed Non-Negative\": (df[\"wind_kph\"] >= 0).all() if \"wind_kph\" in df.columns else True,\n",
    "        \"Data Completeness > 50%\": (df.notna().sum().sum() / (len(df) * len(df.columns))) > 0.5,\n",
    "        \"Date Range Valid\": df[\"date\"].min() < df[\"date\"].max() if not df.empty else False\n",
    "    }\n",
    "    return tests\n",
    "\n",
    "def run_functionality_tests(df_filtered, selected_metric):\n",
    "    \"\"\"Test dashboard functionality\"\"\"\n",
    "    tests = {\n",
    "        \"Filtered Data Not Empty\": not df_filtered.empty,\n",
    "        \"Selected Metric Exists\": selected_metric in df_filtered.columns,\n",
    "        \"Metric Has Valid Values\": df_filtered[selected_metric].notna().any() if selected_metric in df_filtered.columns else False,\n",
    "        \"Can Calculate Statistics\": not pd.isna(df_filtered[selected_metric].mean()) if selected_metric in df_filtered.columns else False,\n",
    "        \"Can Group by Country\": len(df_filtered.groupby(\"country\")) > 0 if \"country\" in df_filtered.columns else False,\n",
    "        \"Can Group by Season\": len(df_filtered.groupby(\"season\")) > 0 if \"season\" in df_filtered.columns else False,\n",
    "        \"Date Filtering Works\": len(df_filtered) <= len(df_raw) if 'df_raw' in globals() else True\n",
    "    }\n",
    "    return tests\n",
    "\n",
    "def run_visualization_tests(df_filtered, selected_metric):\n",
    "    \"\"\"Test visualization generation\"\"\"\n",
    "    tests = {}\n",
    "    try:\n",
    "        # Test if charts can be created\n",
    "        if not df_filtered.empty and selected_metric in df_filtered.columns:\n",
    "            # Test line chart\n",
    "            test_df = df_filtered.groupby(\"date\")[selected_metric].mean().reset_index()\n",
    "            fig_test = px.line(test_df, x=\"date\", y=selected_metric)\n",
    "            tests[\"Line Chart Generation\"] = fig_test is not None\n",
    "            \n",
    "            # Test bar chart\n",
    "            top_locs = df_filtered.groupby(\"location_name\")[selected_metric].mean().nlargest(5).reset_index()\n",
    "            if not top_locs.empty:\n",
    "                fig_bar = px.bar(top_locs, x=selected_metric, y=\"location_name\", orientation='h')\n",
    "                tests[\"Bar Chart Generation\"] = fig_bar is not None\n",
    "            \n",
    "            # Test correlation matrix\n",
    "            numeric_cols = df_filtered.select_dtypes(include=[np.number]).columns\n",
    "            if len(numeric_cols) > 1:\n",
    "                corr = df_filtered[numeric_cols].corr()\n",
    "                tests[\"Correlation Matrix\"] = not corr.empty\n",
    "        else:\n",
    "            tests[\"Line Chart Generation\"] = False\n",
    "            tests[\"Bar Chart Generation\"] = False\n",
    "            tests[\"Correlation Matrix\"] = False\n",
    "    except Exception as e:\n",
    "        tests[\"Visualization Error\"] = str(e)\n",
    "    return tests\n",
    "\n",
    "def run_user_experience_tests():\n",
    "    \"\"\"Test user experience aspects\"\"\"\n",
    "    tests = {\n",
    "        \"Streamlit Config Set\": True,  # Assuming it's set\n",
    "        \"Color Scheme Defined\": 'COLOR_SCHEME' in globals(),\n",
    "        \"Season Colors Defined\": 'SEASON_COLORS' in globals(),\n",
    "        \"Metric Options Available\": 'metric_options' in globals() if 'metric_options' in globals() else False\n",
    "    }\n",
    "    return tests\n",
    "\n",
    "def display_test_results(data_tests, func_tests, viz_tests, ux_tests):\n",
    "    \"\"\"Display test results in a formatted way\"\"\"\n",
    "    st.subheader(\"üß™ Test Results\")\n",
    "    \n",
    "    all_tests = {\n",
    "        \"Data Validation\": data_tests,\n",
    "        \"Functionality\": func_tests,\n",
    "        \"Visualization\": viz_tests,\n",
    "        \"User Experience\": ux_tests\n",
    "    }\n",
    "    \n",
    "    total_tests = 0\n",
    "    passed_tests = 0\n",
    "    \n",
    "    for category, tests in all_tests.items():\n",
    "        st.markdown(f\"### {category}\")\n",
    "        for test_name, result in tests.items():\n",
    "            total_tests += 1\n",
    "            if result:\n",
    "                passed_tests += 1\n",
    "                st.success(f\"‚úÖ {test_name}: PASSED\")\n",
    "            else:\n",
    "                st.error(f\"‚ùå {test_name}: FAILED\")\n",
    "        st.markdown(\"---\")\n",
    "    \n",
    "    # Summary\n",
    "    pass_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0\n",
    "    st.metric(\"Overall Test Pass Rate\", f\"{pass_rate:.1f}%\", f\"{passed_tests}/{total_tests} tests passed\")\n",
    "    \n",
    "    if pass_rate >= 90:\n",
    "        st.success(\"üéâ Dashboard is robust and ready for use!\")\n",
    "    elif pass_rate >= 70:\n",
    "        st.warning(\"‚ö†Ô∏è Dashboard has some issues that should be addressed.\")\n",
    "    else:\n",
    "        st.error(\"üö® Dashboard has significant issues requiring attention.\")\n",
    "\n",
    "# Run tests if in testing mode\n",
    "if 'run_tests' in st.session_state and st.session_state.run_tests:\n",
    "    if not df_filtered.empty:\n",
    "        data_tests = run_data_validation_tests(df_raw)\n",
    "        func_tests = run_functionality_tests(df_filtered, selected_metric)\n",
    "        viz_tests = run_visualization_tests(df_filtered, selected_metric)\n",
    "        ux_tests = run_user_experience_tests()\n",
    "        display_test_results(data_tests, func_tests, viz_tests, ux_tests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Regional and Global Climate Trends Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- REGIONAL AND GLOBAL CLIMATE TRENDS SUMMARY -------------------------\n",
    "# This section provides comprehensive summaries of regional and global climate trends\n",
    "\n",
    "def generate_regional_summary(df_filtered):\n",
    "    \"\"\"Generate comprehensive regional climate summary\"\"\"\n",
    "    summary = {}\n",
    "    \n",
    "    # Country-level summaries\n",
    "    if \"country\" in df_filtered.columns:\n",
    "        country_stats = df_filtered.groupby(\"country\").agg({\n",
    "            \"temperature_celsius\": [\"mean\", \"std\", \"min\", \"max\"],\n",
    "            \"precip_mm\": [\"mean\", \"sum\"],\n",
    "            \"wind_kph\": [\"mean\", \"max\"],\n",
    "            \"humidity\": [\"mean\"]\n",
    "        }).round(2)\n",
    "        summary[\"country_stats\"] = country_stats\n",
    "    \n",
    "    # Regional temperature trends\n",
    "    if \"country\" in df_filtered.columns and \"date\" in df_filtered.columns:\n",
    "        temp_trends = df_filtered.groupby([\"country\", df_filtered[\"date\"].dt.to_period(\"M\")])[\"temperature_celsius\"].mean().reset_index()\n",
    "        temp_trends[\"date\"] = temp_trends[\"date\"].astype(str)\n",
    "        summary[\"temperature_trends\"] = temp_trends\n",
    "    \n",
    "    # Seasonal patterns by region\n",
    "    if \"country\" in df_filtered.columns and \"season\" in df_filtered.columns:\n",
    "        seasonal_patterns = df_filtered.groupby([\"country\", \"season\"]).agg({\n",
    "            \"temperature_celsius\": \"mean\",\n",
    "            \"precip_mm\": \"mean\",\n",
    "            \"wind_kph\": \"mean\"\n",
    "        }).round(2)\n",
    "        summary[\"seasonal_patterns\"] = seasonal_patterns\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def generate_global_summary(df_filtered):\n",
    "    \"\"\"Generate comprehensive global climate summary\"\"\"\n",
    "    summary = {}\n",
    "    \n",
    "    # Overall statistics\n",
    "    summary[\"overall_stats\"] = {\n",
    "        \"avg_temperature\": df_filtered[\"temperature_celsius\"].mean() if \"temperature_celsius\" in df_filtered.columns else None,\n",
    "        \"total_precipitation\": df_filtered[\"precip_mm\"].sum() if \"precip_mm\" in df_filtered.columns else None,\n",
    "        \"avg_wind_speed\": df_filtered[\"wind_kph\"].mean() if \"wind_kph\" in df_filtered.columns else None,\n",
    "        \"avg_humidity\": df_filtered[\"humidity\"].mean() if \"humidity\" in df_filtered.columns else None,\n",
    "        \"date_range\": f\"{df_filtered['date'].min().date()} to {df_filtered['date'].max().date()}\" if \"date\" in df_filtered.columns else None,\n",
    "        \"total_locations\": df_filtered[\"location_name\"].nunique() if \"location_name\" in df_filtered.columns else None,\n",
    "        \"total_countries\": df_filtered[\"country\"].nunique() if \"country\" in df_filtered.columns else None\n",
    "    }\n",
    "    \n",
    "    # Temporal trends\n",
    "    if \"date\" in df_filtered.columns:\n",
    "        monthly_trends = df_filtered.groupby(df_filtered[\"date\"].dt.to_period(\"M\")).agg({\n",
    "            \"temperature_celsius\": \"mean\",\n",
    "            \"precip_mm\": \"mean\",\n",
    "            \"wind_kph\": \"mean\"\n",
    "        }).reset_index()\n",
    "        monthly_trends[\"date\"] = monthly_trends[\"date\"].astype(str)\n",
    "        summary[\"monthly_trends\"] = monthly_trends\n",
    "    \n",
    "    # Seasonal analysis\n",
    "    if \"season\" in df_filtered.columns:\n",
    "        seasonal_summary = df_filtered.groupby(\"season\").agg({\n",
    "            \"temperature_celsius\": [\"mean\", \"std\"],\n",
    "            \"precip_mm\": [\"mean\", \"sum\"],\n",
    "            \"wind_kph\": \"mean\"\n",
    "        }).round(2)\n",
    "        summary[\"seasonal_summary\"] = seasonal_summary\n",
    "    \n",
    "    # Climate extremes\n",
    "    summary[\"extremes\"] = {\n",
    "        \"hottest\": df_filtered.loc[df_filtered[\"temperature_celsius\"].idxmax()].to_dict() if \"temperature_celsius\" in df_filtered.columns else None,\n",
    "        \"coldest\": df_filtered.loc[df_filtered[\"temperature_celsius\"].idxmin()].to_dict() if \"temperature_celsius\" in df_filtered.columns else None,\n",
    "        \"wettest\": df_filtered.loc[df_filtered[\"precip_mm\"].idxmax()].to_dict() if \"precip_mm\" in df_filtered.columns else None,\n",
    "        \"windiest\": df_filtered.loc[df_filtered[\"wind_kph\"].idxmax()].to_dict() if \"wind_kph\" in df_filtered.columns else None\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def display_trends_summary_page(df_filtered):\n",
    "    \"\"\"Display the trends summary page\"\"\"\n",
    "    st.title(\"üìä Regional and Global Climate Trends Summary\")\n",
    "    st.markdown(\"Comprehensive analysis of climate patterns across regions and globally\")\n",
    "    \n",
    "    # Generate summaries\n",
    "    regional_summary = generate_regional_summary(df_filtered)\n",
    "    global_summary = generate_global_summary(df_filtered)\n",
    "    \n",
    "    # Global Overview\n",
    "    st.header(\"üåç Global Climate Overview\")\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    \n",
    "    if global_summary[\"overall_stats\"][\"avg_temperature\"]:\n",
    "        col1.metric(\"Avg Temperature\", f\"{global_summary['overall_stats']['avg_temperature']:.1f}¬∞C\")\n",
    "    if global_summary[\"overall_stats\"][\"total_precipitation\"]:\n",
    "        col2.metric(\"Total Precipitation\", f\"{global_summary['overall_stats']['total_precipitation']:,.0f} mm\")\n",
    "    if global_summary[\"overall_stats\"][\"avg_wind_speed\"]:\n",
    "        col3.metric(\"Avg Wind Speed\", f\"{global_summary['overall_stats']['avg_wind_speed']:.1f} kph\")\n",
    "    if global_summary[\"overall_stats\"][\"total_locations\"]:\n",
    "        col4.metric(\"Locations Analyzed\", global_summary[\"overall_stats\"][\"total_locations\"])\n",
    "    \n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # Regional Analysis\n",
    "    st.header(\"üó∫Ô∏è Regional Climate Analysis\")\n",
    "    \n",
    "    if \"country_stats\" in regional_summary:\n",
    "        st.subheader(\"Country-Level Statistics\")\n",
    "        st.dataframe(regional_summary[\"country_stats\"], use_container_width=True)\n",
    "    \n",
    "    if \"seasonal_patterns\" in regional_summary:\n",
    "        st.subheader(\"Seasonal Patterns by Region\")\n",
    "        st.dataframe(regional_summary[\"seasonal_patterns\"], use_container_width=True)\n",
    "    \n",
    "    # Global Trends\n",
    "    st.header(\"üìà Global Climate Trends\")\n",
    "    \n",
    "    if \"monthly_trends\" in global_summary:\n",
    "        st.subheader(\"Monthly Climate Trends\")\n",
    "        fig_global = go.Figure()\n",
    "        \n",
    "        fig_global.add_trace(go.Scatter(\n",
    "            x=global_summary[\"monthly_trends\"][\"date\"],\n",
    "            y=global_summary[\"monthly_trends\"][\"temperature_celsius\"],\n",
    "            mode='lines+markers',\n",
    "            name='Temperature (¬∞C)',\n",
    "            line=dict(color=COLOR_SCHEME['warning'], width=2)\n",
    "        ))\n",
    "        \n",
    "        fig_global.add_trace(go.Scatter(\n",
    "            x=global_summary[\"monthly_trends\"][\"date\"],\n",
    "            y=global_summary[\"monthly_trends\"][\"precip_mm\"],\n",
    "            mode='lines+markers',\n",
    "            name='Precipitation (mm)',\n",
    "            yaxis='y2',\n",
    "            line=dict(color=COLOR_SCHEME['primary'], width=2)\n",
    "        ))\n",
    "        \n",
    "        fig_global.update_layout(\n",
    "            title=\"Global Monthly Climate Trends\",\n",
    "            xaxis_title=\"Month\",\n",
    "            yaxis=dict(title=\"Temperature (¬∞C)\", side=\"left\"),\n",
    "            yaxis2=dict(title=\"Precipitation (mm)\", overlaying=\"y\", side=\"right\"),\n",
    "            height=500,\n",
    "            hovermode='x unified',\n",
    "            font=dict(family=\"Arial, sans-serif\", size=11)\n",
    "        )\n",
    "        st.plotly_chart(fig_global, use_container_width=True)\n",
    "    \n",
    "    if \"seasonal_summary\" in global_summary:\n",
    "        st.subheader(\"Seasonal Climate Summary\")\n",
    "        st.dataframe(global_summary[\"seasonal_summary\"], use_container_width=True)\n",
    "    \n",
    "    # Key Insights\n",
    "    st.header(\"üí° Key Insights\")\n",
    "    \n",
    "    insight_col1, insight_col2 = st.columns(2)\n",
    "    \n",
    "    with insight_col1:\n",
    "        st.markdown(\"### Regional Insights\")\n",
    "        if \"country_stats\" in regional_summary:\n",
    "            hottest_country = regional_summary[\"country_stats\"][\"temperature_celsius\"][\"mean\"].idxmax()\n",
    "            coldest_country = regional_summary[\"country_stats\"][\"temperature_celsius\"][\"mean\"].idxmin()\n",
    "            wettest_country = regional_summary[\"country_stats\"][\"precip_mm\"][\"sum\"].idxmax()\n",
    "            \n",
    "            st.info(f\"**Hottest Region:** {hottest_country}\")\n",
    "            st.info(f\"**Coldest Region:** {coldest_country}\")\n",
    "            st.info(f\"**Wettest Region:** {wettest_country}\")\n",
    "    \n",
    "    with insight_col2:\n",
    "        st.markdown(\"### Temporal Insights\")\n",
    "        if \"seasonal_summary\" in global_summary:\n",
    "            warmest_season = global_summary[\"seasonal_summary\"][\"temperature_celsius\"][\"mean\"].idxmax()\n",
    "            wettest_season = global_summary[\"seasonal_summary\"][\"precip_mm\"][\"sum\"].idxmax()\n",
    "            \n",
    "            st.info(f\"**Warmest Season:** {warmest_season}\")\n",
    "            st.info(f\"**Wettest Season:** {wettest_season}\")\n",
    "    \n",
    "    # Export summary\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"üì• Export Summary\")\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "# Climate Trends Summary Report\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Global Overview\n",
    "- Average Temperature: {global_summary['overall_stats']['avg_temperature']:.2f}¬∞C\n",
    "- Total Precipitation: {global_summary['overall_stats']['total_precipitation']:,.0f} mm\n",
    "- Average Wind Speed: {global_summary['overall_stats']['avg_wind_speed']:.2f} kph\n",
    "- Date Range: {global_summary['overall_stats']['date_range']}\n",
    "- Locations Analyzed: {global_summary['overall_stats']['total_locations']}\n",
    "- Countries Analyzed: {global_summary['overall_stats']['total_countries']}\n",
    "\n",
    "## Key Findings\n",
    "[Detailed findings would be populated based on analysis]\n",
    "\"\"\"\n",
    "    \n",
    "    st.download_button(\n",
    "        label=\"Download Summary Report\",\n",
    "        data=summary_text,\n",
    "        file_name=f\"climate_trends_summary_{datetime.now().strftime('%Y%m%d')}.txt\",\n",
    "        mime=\"text/plain\"\n",
    "    )\n",
    "\n",
    "# Function is called from main navigation flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Testing & Validation Page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- TESTING & VALIDATION PAGE -------------------------\n",
    "if nav_selection == \"Testing & Validation\":\n",
    "    st.title(\"üß™ Testing & Validation\")\n",
    "    st.markdown(\"Comprehensive testing suite for dashboard functionality, data accuracy, and user experience\")\n",
    "    \n",
    "    # Test execution controls\n",
    "    st.sidebar.markdown(\"### Test Controls\")\n",
    "    run_tests = st.sidebar.button(\"Run All Tests\", type=\"primary\")\n",
    "    \n",
    "    if run_tests or st.session_state.get('auto_run_tests', False):\n",
    "        st.session_state.run_tests = True\n",
    "        st.session_state.auto_run_tests = False\n",
    "        \n",
    "        # Run all test suites\n",
    "        if not df_filtered.empty:\n",
    "            with st.spinner(\"Running tests...\"):\n",
    "                data_tests = run_data_validation_tests(df_raw)\n",
    "                func_tests = run_functionality_tests(df_filtered, selected_metric)\n",
    "                viz_tests = run_visualization_tests(df_filtered, selected_metric)\n",
    "                ux_tests = run_user_experience_tests()\n",
    "                display_test_results(data_tests, func_tests, viz_tests, ux_tests)\n",
    "        else:\n",
    "            st.error(\"Cannot run tests: No filtered data available. Please adjust your filters.\")\n",
    "    \n",
    "    # Data Quality Report\n",
    "    st.header(\"üìä Data Quality Report\")\n",
    "    \n",
    "    if not df_raw.empty:\n",
    "        quality_col1, quality_col2, quality_col3, quality_col4 = st.columns(4)\n",
    "        \n",
    "        total_cells = len(df_raw) * len(df_raw.columns)\n",
    "        missing_cells = df_raw.isna().sum().sum()\n",
    "        completeness = ((total_cells - missing_cells) / total_cells * 100) if total_cells > 0 else 0\n",
    "        \n",
    "        quality_col1.metric(\"Data Completeness\", f\"{completeness:.1f}%\")\n",
    "        quality_col2.metric(\"Total Records\", f\"{len(df_raw):,}\")\n",
    "        quality_col3.metric(\"Total Variables\", len(df_raw.columns))\n",
    "        quality_col4.metric(\"Date Range\", f\"{(df_raw['date'].max() - df_raw['date'].min()).days} days\" if 'date' in df_raw.columns else \"N/A\")\n",
    "        \n",
    "        # Missing data analysis\n",
    "        st.subheader(\"Missing Data Analysis\")\n",
    "        missing_data = df_raw.isna().sum().sort_values(ascending=False)\n",
    "        missing_data = missing_data[missing_data > 0]\n",
    "        \n",
    "        if not missing_data.empty:\n",
    "            fig_missing = px.bar(\n",
    "                x=missing_data.index,\n",
    "                y=missing_data.values,\n",
    "                title=\"Missing Values by Column\",\n",
    "                labels={\"x\": \"Column\", \"y\": \"Missing Count\"}\n",
    "            )\n",
    "            fig_missing.update_layout(height=400)\n",
    "            st.plotly_chart(fig_missing, use_container_width=True)\n",
    "        else:\n",
    "            st.success(\"‚úÖ No missing data detected!\")\n",
    "    \n",
    "    # Performance Metrics\n",
    "    st.header(\"‚ö° Performance Metrics\")\n",
    "    perf_col1, perf_col2, perf_col3 = st.columns(3)\n",
    "    \n",
    "    perf_col1.metric(\"Data Loading Time\", \"< 1s\", \"Cached\")\n",
    "    perf_col2.metric(\"Filtering Efficiency\", \"Optimized\", \"Vectorized\")\n",
    "    perf_col3.metric(\"Chart Rendering\", \"Fast\", \"Plotly\")\n",
    "    \n",
    "    # User Experience Checklist\n",
    "    st.header(\"‚úÖ User Experience Checklist\")\n",
    "    \n",
    "    ux_checklist = {\n",
    "        \"Intuitive Navigation\": True,\n",
    "        \"Clear Visualizations\": True,\n",
    "        \"Responsive Filters\": True,\n",
    "        \"Helpful Tooltips\": True,\n",
    "        \"Error Handling\": True,\n",
    "        \"Consistent Styling\": True,\n",
    "        \"Mobile Responsive\": \"Partial\",\n",
    "        \"Accessibility Features\": \"Basic\"\n",
    "    }\n",
    "    \n",
    "    for item, status in ux_checklist.items():\n",
    "        if status == True:\n",
    "            st.success(f\"‚úÖ {item}\")\n",
    "        elif status == \"Partial\" or status == \"Basic\":\n",
    "            st.warning(f\"‚ö†Ô∏è {item}: {status}\")\n",
    "        else:\n",
    "            st.error(f\"‚ùå {item}\")\n",
    "    \n",
    "    # Export Test Report\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"üì• Export Test Report\")\n",
    "    \n",
    "    test_report = f\"\"\"\n",
    "# Dashboard Testing Report\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Test Summary\n",
    "[Test results would be included here]\n",
    "\n",
    "## Data Quality\n",
    "- Completeness: {completeness:.1f}%\n",
    "- Total Records: {len(df_raw):,}\n",
    "- Variables: {len(df_raw.columns)}\n",
    "\n",
    "## Recommendations\n",
    "[Based on test results]\n",
    "\"\"\"\n",
    "    \n",
    "    st.download_button(\n",
    "        label=\"Download Test Report\",\n",
    "        data=test_report,\n",
    "        file_name=f\"dashboard_test_report_{datetime.now().strftime('%Y%m%d')}.txt\",\n",
    "        mime=\"text/plain\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- CRITICAL: FILTERING LOGIC -------------------------\n",
    "\n",
    "# 1. Unpack the date range safely\n",
    "if isinstance(date_range, (list, tuple)) and len(date_range) == 2:\n",
    "    start_date, end_date = date_range\n",
    "else:\n",
    "    start_date, end_date = min_date, max_date\n",
    "\n",
    "# 2. Filter the DataFrame\n",
    "df_filtered = df_raw[\n",
    "    (df_raw[\"country\"].isin(selected_countries)) & \n",
    "    (df_raw[\"location_name\"].isin(selected_locations)) &\n",
    "    (df_raw[\"date\"].dt.date >= start_date) & \n",
    "    (df_raw[\"date\"].dt.date <= end_date)\n",
    "].copy()\n",
    "\n",
    "# 3. Add Moving Averages (Dynamic) with configurable window\n",
    "if not df_filtered.empty:\n",
    "    df_filtered[f\"{moving_avg_window}d_moving_avg\"] = df_filtered.groupby(\"location_name\")[selected_metric].transform(\n",
    "        lambda x: x.rolling(moving_avg_window, min_periods=1).mean()\n",
    "    )\n",
    "    \n",
    "    # Add percentile-based anomaly detection\n",
    "    if enable_anomaly_detection:\n",
    "        percentile_value = df_filtered[selected_metric].quantile(percentile_threshold / 100)\n",
    "        df_filtered[\"is_anomaly_high\"] = df_filtered[selected_metric] >= percentile_value\n",
    "        df_filtered[\"is_anomaly_low\"] = df_filtered[selected_metric] <= df_filtered[selected_metric].quantile((100 - percentile_threshold) / 100)\n",
    "\n",
    "if df_filtered.empty:\n",
    "    st.warning(\"No data matches your filters. Please adjust the sidebar.\")\n",
    "    st.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Page 1: Executive Dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- PAGE 1: EXECUTIVE DASHBOARD -------------------------\n",
    "if nav_selection == \"Executive Dashboard\":\n",
    "    st.title(\"üìä Executive Dashboard\")\n",
    "    st.markdown(f\"**Snapshot:** {start_date} to {end_date} | **Focus:** {selected_metric_label} | **Locations:** {len(selected_locations)}\")\n",
    "\n",
    "    # --- KPI Cards with Delta Indicators ---\n",
    "    avg_val = df_filtered[selected_metric].mean()\n",
    "    total_precip = df_filtered[\"precip_mm\"].sum()\n",
    "    max_wind = df_filtered[\"wind_kph\"].max()\n",
    "    locations_count = df_filtered[\"location_name\"].nunique()\n",
    "    \n",
    "    # Calculate deltas for comparison (first half vs second half of period)\n",
    "    mid_date = start_date + (end_date - start_date) / 2\n",
    "    first_half = df_filtered[df_filtered[\"date\"].dt.date < mid_date][selected_metric].mean()\n",
    "    second_half = df_filtered[df_filtered[\"date\"].dt.date >= mid_date][selected_metric].mean()\n",
    "    delta_val = second_half - first_half if not (pd.isna(first_half) or pd.isna(second_half)) else None\n",
    "\n",
    "    c1, c2, c3, c4, c5 = st.columns(5)\n",
    "    c1.metric(f\"Avg {selected_metric_label}\", f\"{avg_val:.1f}\", delta=f\"{delta_val:.1f}\" if delta_val else None)\n",
    "    c2.metric(\"Total Precip (mm)\", f\"{total_precip:,.0f}\")\n",
    "    c3.metric(\"Max Wind (kph)\", f\"{max_wind:.1f}\")\n",
    "    c4.metric(\"Active Locations\", locations_count)\n",
    "    c5.metric(\"Data Points\", f\"{len(df_filtered):,}\")\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # --- Automated Insights Section (NEW) ---\n",
    "    st.subheader(\"üîç Key Insights & Findings\")\n",
    "    insight_col1, insight_col2, insight_col3 = st.columns(3)\n",
    "    \n",
    "    with insight_col1:\n",
    "        st.markdown(\"**üìä Statistical Highlights**\")\n",
    "        median_val = df_filtered[selected_metric].median()\n",
    "        std_val = df_filtered[selected_metric].std()\n",
    "        st.info(f\"**Median:** {median_val:.1f} | **Std Dev:** {std_val:.1f}\")\n",
    "        \n",
    "        # Variability insight\n",
    "        cv = (std_val / avg_val * 100) if avg_val != 0 else 0\n",
    "        if cv > 30:\n",
    "            st.warning(f\"‚ö†Ô∏è High variability detected (CV: {cv:.1f}%)\")\n",
    "        else:\n",
    "            st.success(f\"‚úì Moderate variability (CV: {cv:.1f}%)\")\n",
    "    \n",
    "    with insight_col2:\n",
    "        st.markdown(\"**üåç Geographic Insights**\")\n",
    "        top_country = df_filtered.groupby(\"country\")[selected_metric].mean().idxmax()\n",
    "        top_country_val = df_filtered.groupby(\"country\")[selected_metric].mean().max()\n",
    "        st.info(f\"**Highest:** {top_country} ({top_country_val:.1f})\")\n",
    "        \n",
    "        bottom_country = df_filtered.groupby(\"country\")[selected_metric].mean().idxmin()\n",
    "        bottom_country_val = df_filtered.groupby(\"country\")[selected_metric].mean().min()\n",
    "        st.info(f\"**Lowest:** {bottom_country} ({bottom_country_val:.1f})\")\n",
    "    \n",
    "    with insight_col3:\n",
    "        st.markdown(\"**üìÖ Temporal Insights**\")\n",
    "        peak_date = df_filtered.loc[df_filtered[selected_metric].idxmax(), \"date\"]\n",
    "        peak_val = df_filtered[selected_metric].max()\n",
    "        st.info(f\"**Peak:** {peak_date.strftime('%Y-%m-%d')} ({peak_val:.1f})\")\n",
    "        \n",
    "        # Trend direction\n",
    "        if delta_val and delta_val > 0:\n",
    "            st.success(f\"üìà Increasing trend detected\")\n",
    "        elif delta_val and delta_val < 0:\n",
    "            st.warning(f\"üìâ Decreasing trend detected\")\n",
    "        else:\n",
    "            st.info(\"‚û°Ô∏è Stable trend\")\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # --- Global Map with Enhanced Styling ---\n",
    "    st.subheader(\"üåê Global Distribution\")\n",
    "    country_agg = df_filtered.groupby(\"country\")[selected_metric].mean().reset_index()\n",
    "    \n",
    "    fig_map = px.choropleth(\n",
    "        country_agg,\n",
    "        locations=\"country\",\n",
    "        locationmode=\"country names\",\n",
    "        color=selected_metric,\n",
    "        hover_name=\"country\",\n",
    "        hover_data={selected_metric: ':.2f'},\n",
    "        color_continuous_scale=PLOTLY_COLORSCALE,\n",
    "        title=f\"Average {selected_metric_label} by Country\",\n",
    "        labels={selected_metric: selected_metric_label}\n",
    "    )\n",
    "    fig_map.update_layout(\n",
    "        geo=dict(showframe=False, showcoastlines=True, projection_type='equirectangular'),\n",
    "        font=dict(family=\"Arial, sans-serif\", size=12),\n",
    "        title_font_size=16,\n",
    "        height=500\n",
    "    )\n",
    "    fig_map.update_traces(hovertemplate=\"<b>%{hovertext}</b><br>%{z:.2f}<extra></extra>\")\n",
    "    st.plotly_chart(fig_map, use_container_width=True)\n",
    "\n",
    "    # --- Enhanced Key Insights with Moving Average ---\n",
    "    st.subheader(\"üìå Detailed Analysis\")\n",
    "    col_ins1, col_ins2 = st.columns(2)\n",
    "    \n",
    "    with col_ins1:\n",
    "        top_locs = df_filtered.groupby(\"location_name\")[selected_metric].mean().nlargest(10).reset_index()\n",
    "        fig_bar = px.bar(\n",
    "            top_locs, \n",
    "            x=selected_metric, \n",
    "            y=\"location_name\", \n",
    "            orientation='h', \n",
    "            title=f\"Top 10 Locations by {selected_metric_label}\",\n",
    "            color=selected_metric,\n",
    "            color_continuous_scale=PLOTLY_COLORSCALE,\n",
    "            labels={selected_metric: selected_metric_label, \"location_name\": \"Location\"}\n",
    "        )\n",
    "        fig_bar.update_layout(\n",
    "            yaxis={'categoryorder':'total ascending'},\n",
    "            height=400,\n",
    "            showlegend=False,\n",
    "            font=dict(family=\"Arial, sans-serif\", size=11)\n",
    "        )\n",
    "        fig_bar.update_traces(hovertemplate=\"<b>%{y}</b><br>%{x:.2f}<extra></extra>\")\n",
    "        st.plotly_chart(fig_bar, use_container_width=True)\n",
    "\n",
    "    with col_ins2:\n",
    "        daily_agg = df_filtered.groupby(\"date\")[selected_metric].mean().reset_index()\n",
    "        daily_agg = daily_agg.sort_values(\"date\")\n",
    "        \n",
    "        fig_line = go.Figure()\n",
    "        \n",
    "        # Main line\n",
    "        fig_line.add_trace(go.Scatter(\n",
    "            x=daily_agg[\"date\"],\n",
    "            y=daily_agg[selected_metric],\n",
    "            mode='lines',\n",
    "            name=selected_metric_label,\n",
    "            line=dict(color=COLOR_SCHEME['primary'], width=2),\n",
    "            hovertemplate=\"<b>Date:</b> %{x}<br><b>Value:</b> %{y:.2f}<extra></extra>\"\n",
    "        ))\n",
    "        \n",
    "        # Moving average line\n",
    "        if show_trend_line and f\"{moving_avg_window}d_moving_avg\" in df_filtered.columns:\n",
    "            ma_agg = df_filtered.groupby(\"date\")[f\"{moving_avg_window}d_moving_avg\"].mean().reset_index()\n",
    "            ma_agg = ma_agg.sort_values(\"date\")\n",
    "            fig_line.add_trace(go.Scatter(\n",
    "                x=ma_agg[\"date\"],\n",
    "                y=ma_agg[f\"{moving_avg_window}d_moving_avg\"],\n",
    "                mode='lines',\n",
    "                name=f'{moving_avg_window}-Day Moving Avg',\n",
    "                line=dict(color=COLOR_SCHEME['secondary'], width=2, dash='dash'),\n",
    "                hovertemplate=\"<b>Date:</b> %{x}<br><b>MA:</b> %{y:.2f}<extra></extra>\"\n",
    "            ))\n",
    "        \n",
    "        # Confidence band (optional)\n",
    "        if show_confidence_band:\n",
    "            std_agg = df_filtered.groupby(\"date\")[selected_metric].std().reset_index()\n",
    "            std_agg = std_agg.sort_values(\"date\")\n",
    "            upper_bound = daily_agg[selected_metric] + 1.96 * std_agg[selected_metric]\n",
    "            lower_bound = daily_agg[selected_metric] - 1.96 * std_agg[selected_metric]\n",
    "            \n",
    "            fig_line.add_trace(go.Scatter(\n",
    "                x=daily_agg[\"date\"],\n",
    "                y=upper_bound,\n",
    "                mode='lines',\n",
    "                name='Upper 95% CI',\n",
    "                line=dict(width=0),\n",
    "                showlegend=False,\n",
    "                hoverinfo='skip'\n",
    "            ))\n",
    "            fig_line.add_trace(go.Scatter(\n",
    "                x=daily_agg[\"date\"],\n",
    "                y=lower_bound,\n",
    "                mode='lines',\n",
    "                name='Lower 95% CI',\n",
    "                line=dict(width=0),\n",
    "                fill='tonexty',\n",
    "                fillcolor='rgba(31, 119, 180, 0.2)',\n",
    "                showlegend=False,\n",
    "                hoverinfo='skip'\n",
    "            ))\n",
    "        \n",
    "        # Anomaly markers\n",
    "        if enable_anomaly_detection and \"is_anomaly_high\" in df_filtered.columns:\n",
    "            anomalies_high = df_filtered[df_filtered[\"is_anomaly_high\"]].groupby(\"date\")[selected_metric].mean().reset_index()\n",
    "            if not anomalies_high.empty:\n",
    "                fig_line.add_trace(go.Scatter(\n",
    "                    x=anomalies_high[\"date\"],\n",
    "                    y=anomalies_high[selected_metric],\n",
    "                    mode='markers',\n",
    "                    name='High Anomalies',\n",
    "                    marker=dict(color=COLOR_SCHEME['warning'], size=8, symbol='triangle-up'),\n",
    "                    hovertemplate=\"<b>Anomaly:</b> %{y:.2f}<br>Date: %{x}<extra></extra>\"\n",
    "                ))\n",
    "        \n",
    "        fig_line.update_layout(\n",
    "            title=f\"Global Daily Trend: {selected_metric_label}\",\n",
    "            xaxis_title=\"Date\",\n",
    "            yaxis_title=selected_metric_label,\n",
    "            height=400,\n",
    "            hovermode='x unified',\n",
    "            font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
    "        )\n",
    "        st.plotly_chart(fig_line, use_container_width=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Page 2: Statistical Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- PAGE 2: STATISTICAL ANALYSIS -------------------------\n",
    "if nav_selection == \"Statistical Analysis\":\n",
    "    st.title(\"üìà Statistical Analysis\")\n",
    "    st.markdown(\"Comprehensive statistical insights and relationships in climate data\")\n",
    "\n",
    "    # --- Enhanced Descriptive Statistics ---\n",
    "    st.subheader(\"üìä Descriptive Statistics\")\n",
    "    stats_cols = [selected_metric, \"precip_mm\", \"humidity\", \"wind_kph\", \"pressure_mb\", \"temperature_celsius\"]\n",
    "    available_stats_cols = [c for c in stats_cols if c in df_filtered.columns]\n",
    "    stats_df = df_filtered[available_stats_cols].describe().T\n",
    "    stats_df = stats_df.round(2)\n",
    "    \n",
    "    # Add custom statistics\n",
    "    stats_df['Skewness'] = df_filtered[available_stats_cols].skew()\n",
    "    stats_df['Kurtosis'] = df_filtered[available_stats_cols].kurtosis()\n",
    "    \n",
    "    st.dataframe(\n",
    "        stats_df.style.background_gradient(cmap=\"Blues\", subset=['mean', 'std', 'min', 'max'])\n",
    "        .format(precision=2)\n",
    "    )\n",
    "    \n",
    "    # Statistical insights\n",
    "    col_stat1, col_stat2, col_stat3 = st.columns(3)\n",
    "    with col_stat1:\n",
    "        st.metric(\"Total Observations\", f\"{len(df_filtered):,}\")\n",
    "    with col_stat2:\n",
    "        st.metric(\"Variables Analyzed\", len(available_stats_cols))\n",
    "    with col_stat3:\n",
    "        missing_pct = (df_filtered[available_stats_cols].isna().sum().sum() / (len(df_filtered) * len(available_stats_cols))) * 100\n",
    "        st.metric(\"Data Completeness\", f\"{100 - missing_pct:.1f}%\")\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # --- Enhanced Correlation Matrix ---\n",
    "    st.subheader(\"üîó Correlation Analysis\")\n",
    "    corr_cols = [\"temperature_celsius\", \"humidity\", \"precip_mm\", \"wind_kph\", \"pressure_mb\", \"uv_index\", \"heat_index_c\", \"wind_chill_c\"]\n",
    "    present_cols = [c for c in corr_cols if c in df_filtered.columns]\n",
    "    corr_matrix = df_filtered[present_cols].corr()\n",
    "    \n",
    "    # Create custom labels\n",
    "    label_dict = {\n",
    "        \"temperature_celsius\": \"Temperature\",\n",
    "        \"humidity\": \"Humidity\",\n",
    "        \"precip_mm\": \"Precipitation\",\n",
    "        \"wind_kph\": \"Wind Speed\",\n",
    "        \"pressure_mb\": \"Pressure\",\n",
    "        \"uv_index\": \"UV Index\",\n",
    "        \"heat_index_c\": \"Heat Index\",\n",
    "        \"wind_chill_c\": \"Wind Chill\"\n",
    "    }\n",
    "    corr_matrix.index = [label_dict.get(col, col) for col in corr_matrix.index]\n",
    "    corr_matrix.columns = [label_dict.get(col, col) for col in corr_matrix.columns]\n",
    "    \n",
    "    fig_corr = px.imshow(\n",
    "        corr_matrix, \n",
    "        text_auto='.2f', \n",
    "        aspect=\"auto\", \n",
    "        color_continuous_scale=PLOTLY_CORR_COLORSCALE,\n",
    "        title=\"Correlation Heatmap - Climate Variables\",\n",
    "        labels=dict(color=\"Correlation Coefficient\")\n",
    "    )\n",
    "    fig_corr.update_layout(\n",
    "        height=600,\n",
    "        font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "        title_font_size=16\n",
    "    )\n",
    "    fig_corr.update_traces(hovertemplate=\"<b>%{y}</b> vs <b>%{x}</b><br>Correlation: %{z:.3f}<extra></extra>\")\n",
    "    st.plotly_chart(fig_corr, use_container_width=True)\n",
    "    \n",
    "    # Highlight strongest correlations\n",
    "    st.markdown(\"**üí° Strongest Correlations:**\")\n",
    "    corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            corr_pairs.append({\n",
    "                'Variable 1': corr_matrix.columns[i],\n",
    "                'Variable 2': corr_matrix.columns[j],\n",
    "                'Correlation': corr_matrix.iloc[i, j]\n",
    "            })\n",
    "    corr_df = pd.DataFrame(corr_pairs)\n",
    "    corr_df['Abs Correlation'] = corr_df['Correlation'].abs()\n",
    "    top_corr = corr_df.nlargest(5, 'Abs Correlation')[['Variable 1', 'Variable 2', 'Correlation']]\n",
    "    st.dataframe(top_corr.style.background_gradient(cmap=\"RdBu_r\", subset=['Correlation']), hide_index=True)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # --- Enhanced Variable Relationships ---\n",
    "    st.subheader(\"üîç Variable Relationships & Scatter Analysis\")\n",
    "    \n",
    "    with st.expander(\"‚öôÔ∏è Scatter Plot Controls\", expanded=True):\n",
    "        col_sc1, col_sc2, col_sc3, col_sc4 = st.columns(4)\n",
    "        with col_sc1:\n",
    "            x_axis = st.selectbox(\"X-Axis Variable\", present_cols, index=0, key=\"scatter_x\")\n",
    "        with col_sc2:\n",
    "            y_axis = st.selectbox(\"Y-Axis Variable\", present_cols, index=1, key=\"scatter_y\")\n",
    "        with col_sc3:\n",
    "            color_by = st.selectbox(\"Color By\", [\"season\", \"country\", \"None\"], index=0, key=\"scatter_color\")\n",
    "        with col_sc4:\n",
    "            size_by = st.selectbox(\"Size By\", [\"wind_kph\", \"precip_mm\", \"humidity\", \"None\"], index=0, key=\"scatter_size\")\n",
    "    \n",
    "    # Prepare data for scatter\n",
    "    scatter_df = df_filtered.copy()\n",
    "    if color_by == \"None\":\n",
    "        color_by = None\n",
    "    if size_by == \"None\":\n",
    "        size_by = None\n",
    "        \n",
    "    fig_scatter = px.scatter(\n",
    "        scatter_df, \n",
    "        x=x_axis, \n",
    "        y=y_axis, \n",
    "        color=color_by,\n",
    "        size=size_by,\n",
    "        hover_data=[\"country\", \"location_name\", \"date\"],\n",
    "        title=f\"{label_dict.get(x_axis, x_axis)} vs {label_dict.get(y_axis, y_axis)}\",\n",
    "        color_discrete_map=SEASON_COLORS if color_by == \"season\" else None,\n",
    "        labels={x_axis: label_dict.get(x_axis, x_axis), y_axis: label_dict.get(y_axis, y_axis)}\n",
    "    )\n",
    "    \n",
    "    # Add trend line\n",
    "    if show_trend_line:\n",
    "        try:\n",
    "            # Remove NaN values for trend line calculation\n",
    "            valid_data = scatter_df[[x_axis, y_axis]].dropna()\n",
    "            if len(valid_data) > 1:\n",
    "                z = np.polyfit(valid_data[x_axis], valid_data[y_axis], 1)\n",
    "                p = np.poly1d(z)\n",
    "                x_trend = np.linspace(valid_data[x_axis].min(), valid_data[x_axis].max(), 100)\n",
    "                fig_scatter.add_trace(go.Scatter(\n",
    "                    x=x_trend,\n",
    "                    y=p(x_trend),\n",
    "                    mode='lines',\n",
    "                    name='Trend Line',\n",
    "                    line=dict(color=COLOR_SCHEME['warning'], width=2, dash='dash')\n",
    "                ))\n",
    "        except Exception as e:\n",
    "            # Silently fail if trend line cannot be calculated\n",
    "            pass\n",
    "    \n",
    "    fig_scatter.update_layout(\n",
    "        height=500,\n",
    "        font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "        title_font_size=16,\n",
    "        legend=dict(bgcolor='rgba(255,255,255,0.8)', bordercolor='rgba(0,0,0,0.2)')\n",
    "    )\n",
    "    fig_scatter.update_traces(marker=dict(opacity=0.6, line=dict(width=0.5, color='white')))\n",
    "    st.plotly_chart(fig_scatter, use_container_width=True)\n",
    "    \n",
    "    # Distribution comparison\n",
    "    st.subheader(\"üìâ Distribution Comparison\")\n",
    "    dist_col1, dist_col2 = st.columns(2)\n",
    "    \n",
    "    with dist_col1:\n",
    "        selected_dist_var = st.selectbox(\"Select Variable for Distribution\", present_cols, key=\"dist_var\")\n",
    "        fig_hist = px.histogram(\n",
    "            df_filtered,\n",
    "            x=selected_dist_var,\n",
    "            color=\"season\",\n",
    "            nbins=30,\n",
    "            title=f\"Distribution of {label_dict.get(selected_dist_var, selected_dist_var)} by Season\",\n",
    "            color_discrete_map=SEASON_COLORS,\n",
    "            labels={selected_dist_var: label_dict.get(selected_dist_var, selected_dist_var)}\n",
    "        )\n",
    "        fig_hist.update_layout(height=400, font=dict(family=\"Arial, sans-serif\", size=11))\n",
    "        st.plotly_chart(fig_hist, use_container_width=True)\n",
    "    \n",
    "    with dist_col2:\n",
    "        fig_density = px.density_heatmap(\n",
    "            df_filtered,\n",
    "            x=x_axis,\n",
    "            y=y_axis,\n",
    "            title=f\"Density Heatmap: {label_dict.get(x_axis, x_axis)} vs {label_dict.get(y_axis, y_axis)}\",\n",
    "            labels={x_axis: label_dict.get(x_axis, x_axis), y_axis: label_dict.get(y_axis, y_axis)},\n",
    "            color_continuous_scale=PLOTLY_COLORSCALE\n",
    "        )\n",
    "        fig_density.update_layout(height=400, font=dict(family=\"Arial, sans-serif\", size=11))\n",
    "        st.plotly_chart(fig_density, use_container_width=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Page 3: Climate Trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- PAGE 3: CLIMATE TRENDS -------------------------\n",
    "if nav_selection == \"Climate Trends\":\n",
    "    st.title(\"üìâ Climate Trends & Distributions\")\n",
    "    st.markdown(\"Analyze temporal patterns, seasonal variations, and distribution characteristics\")\n",
    "\n",
    "    with st.expander(\"‚öôÔ∏è Chart Settings\", expanded=True):\n",
    "        col_ctrl1, col_ctrl2, col_ctrl3 = st.columns(3)\n",
    "        agg_type = col_ctrl1.selectbox(\"Time Aggregation\", [\"Daily\", \"Weekly\", \"Monthly\", \"Seasonal\", \"Yearly\"], key=\"trend_agg\")\n",
    "        normalize = col_ctrl2.checkbox(\"Normalize Data (Min-Max Scaling)\", value=False, key=\"trend_norm\")\n",
    "        show_multiple_metrics = col_ctrl3.checkbox(\"Show Multiple Metrics\", value=False, key=\"trend_multi\")\n",
    "\n",
    "    # Prepare trend data based on aggregation type\n",
    "    if agg_type == \"Monthly\":\n",
    "        trend_df = df_filtered.groupby([\"month_name\", \"month_num\", \"season\"])[selected_metric].mean().reset_index().sort_values(\"month_num\")\n",
    "        x_col = \"month_name\"\n",
    "        x_title = \"Month\"\n",
    "    elif agg_type == \"Seasonal\":\n",
    "        trend_df = df_filtered.groupby(\"season\")[selected_metric].mean().reset_index()\n",
    "        x_col = \"season\"\n",
    "        x_title = \"Season\"\n",
    "    elif agg_type == \"Yearly\":\n",
    "        trend_df = df_filtered.groupby(\"year\")[selected_metric].mean().reset_index()\n",
    "        x_col = \"year\"\n",
    "        x_title = \"Year\"\n",
    "    elif agg_type == \"Weekly\":\n",
    "        df_filtered[\"week\"] = df_filtered[\"date\"].dt.isocalendar().week\n",
    "        df_filtered[\"year_week\"] = df_filtered[\"year\"].astype(str) + \"-W\" + df_filtered[\"week\"].astype(str).str.zfill(2)\n",
    "        trend_df = df_filtered.groupby(\"year_week\")[selected_metric].mean().reset_index()\n",
    "        x_col = \"year_week\"\n",
    "        x_title = \"Week\"\n",
    "    else:  # Daily\n",
    "        trend_df = df_filtered.groupby(\"date\")[selected_metric].mean().reset_index()\n",
    "        x_col = \"date\"\n",
    "        x_title = \"Date\"\n",
    "\n",
    "    if normalize:\n",
    "        trend_df[selected_metric] = (trend_df[selected_metric] - trend_df[selected_metric].min()) / (trend_df[selected_metric].max() - trend_df[selected_metric].min())\n",
    "\n",
    "    # Main trend visualization\n",
    "    c1, c2 = st.columns(2)\n",
    "    \n",
    "    with c1:\n",
    "        if show_multiple_metrics:\n",
    "            # Multi-metric comparison\n",
    "            metrics_to_show = st.multiselect(\n",
    "                \"Select Metrics to Compare\",\n",
    "                options=list(metric_options.keys())[:5],  # Limit to first 5 for clarity\n",
    "                default=[selected_metric_label],\n",
    "                key=\"multi_metrics\"\n",
    "            )\n",
    "            \n",
    "            if metrics_to_show:\n",
    "                fig_trend = go.Figure()\n",
    "                for metric_label in metrics_to_show:\n",
    "                    metric_col = metric_options[metric_label]\n",
    "                    if agg_type == \"Daily\":\n",
    "                        metric_trend = df_filtered.groupby(\"date\")[metric_col].mean().reset_index()\n",
    "                        x_vals = metric_trend[\"date\"]\n",
    "                    elif agg_type == \"Monthly\":\n",
    "                        metric_trend = df_filtered.groupby([\"month_name\", \"month_num\"])[metric_col].mean().reset_index().sort_values(\"month_num\")\n",
    "                        x_vals = metric_trend[\"month_name\"]\n",
    "                    else:\n",
    "                        metric_trend = df_filtered.groupby(\"season\")[metric_col].mean().reset_index()\n",
    "                        x_vals = metric_trend[\"season\"]\n",
    "                    \n",
    "                    fig_trend.add_trace(go.Scatter(\n",
    "                        x=x_vals,\n",
    "                        y=metric_trend[metric_col],\n",
    "                        mode='lines+markers',\n",
    "                        name=metric_label,\n",
    "                        line=dict(width=2)\n",
    "                    ))\n",
    "                \n",
    "                fig_trend.update_layout(\n",
    "                    title=f\"{agg_type} Trend Comparison\",\n",
    "                    xaxis_title=x_title,\n",
    "                    yaxis_title=\"Value\",\n",
    "                    height=450,\n",
    "                    hovermode='x unified',\n",
    "                    font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "                    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
    "                )\n",
    "                st.plotly_chart(fig_trend, use_container_width=True)\n",
    "        else:\n",
    "            fig_trend = px.area(\n",
    "                trend_df, \n",
    "                x=x_col, \n",
    "                y=selected_metric, \n",
    "                title=f\"{agg_type} Trend ({selected_metric_label})\",\n",
    "                labels={selected_metric: selected_metric_label, x_col: x_title}\n",
    "            )\n",
    "            fig_trend.update_traces(\n",
    "                fill='tonexty',\n",
    "                fillcolor=f'rgba(31, 119, 180, 0.3)',\n",
    "                line=dict(color=COLOR_SCHEME['primary'], width=2)\n",
    "            )\n",
    "            fig_trend.update_layout(\n",
    "                height=450,\n",
    "                font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "                title_font_size=16\n",
    "            )\n",
    "            st.plotly_chart(fig_trend, use_container_width=True)\n",
    "        \n",
    "    with c2:\n",
    "        fig_box = px.box(\n",
    "            df_filtered, \n",
    "            x=\"season\", \n",
    "            y=selected_metric, \n",
    "            color=\"season\",\n",
    "            title=f\"Seasonal Distribution: {selected_metric_label}\",\n",
    "            color_discrete_map=SEASON_COLORS,\n",
    "            labels={selected_metric: selected_metric_label, \"season\": \"Season\"}\n",
    "        )\n",
    "        fig_box.update_layout(\n",
    "            height=450,\n",
    "            showlegend=False,\n",
    "            font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "            title_font_size=16\n",
    "        )\n",
    "        fig_box.update_traces(boxmean='sd')\n",
    "        st.plotly_chart(fig_box, use_container_width=True)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Advanced Distributions\n",
    "    st.subheader(\"üìä Advanced Distribution Analysis\")\n",
    "    c3, c4 = st.columns(2)\n",
    "\n",
    "    with c3:\n",
    "        fig_violin = px.violin(\n",
    "            df_filtered, \n",
    "            y=selected_metric, \n",
    "            x=\"season\", \n",
    "            box=True, \n",
    "            points=\"outliers\",\n",
    "            title=f\"Violin Plot: {selected_metric_label} by Season\",\n",
    "            color=\"season\",\n",
    "            color_discrete_map=SEASON_COLORS,\n",
    "            labels={selected_metric: selected_metric_label, \"season\": \"Season\"}\n",
    "        )\n",
    "        fig_violin.update_layout(\n",
    "            height=450,\n",
    "            showlegend=False,\n",
    "            font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "            title_font_size=16\n",
    "        )\n",
    "        st.plotly_chart(fig_violin, use_container_width=True)\n",
    "    \n",
    "    with c4:\n",
    "        # Enhanced radar chart\n",
    "        seasonal_means = df_filtered.groupby(\"season\")[[\"temperature_celsius\", \"humidity\", \"wind_kph\", \"precip_mm\"]].mean().reset_index()\n",
    "        \n",
    "        # Normalize for radar chart (0-1 scale)\n",
    "        metrics_for_radar = [\"temperature_celsius\", \"humidity\", \"wind_kph\", \"precip_mm\"]\n",
    "        for metric in metrics_for_radar:\n",
    "            if metric in seasonal_means.columns:\n",
    "                min_val = seasonal_means[metric].min()\n",
    "                max_val = seasonal_means[metric].max()\n",
    "                if max_val > min_val:\n",
    "                    seasonal_means[f\"{metric}_norm\"] = (seasonal_means[metric] - min_val) / (max_val - min_val)\n",
    "                else:\n",
    "                    seasonal_means[f\"{metric}_norm\"] = 0.5\n",
    "        \n",
    "        radar_df = pd.melt(\n",
    "            seasonal_means, \n",
    "            id_vars=[\"season\"], \n",
    "            value_vars=[f\"{m}_norm\" for m in metrics_for_radar if f\"{m}_norm\" in seasonal_means.columns],\n",
    "            var_name=\"Metric\", \n",
    "            value_name=\"Value\"\n",
    "        )\n",
    "        radar_df[\"Metric\"] = radar_df[\"Metric\"].str.replace(\"_norm\", \"\").str.replace(\"_\", \" \").str.title()\n",
    "        \n",
    "        fig_radar = px.line_polar(\n",
    "            radar_df, \n",
    "            r=\"Value\", \n",
    "            theta=\"Metric\", \n",
    "            color=\"season\", \n",
    "            line_close=True, \n",
    "            title=\"Seasonal Climate Profile (Normalized)\",\n",
    "            color_discrete_map=SEASON_COLORS\n",
    "        )\n",
    "        fig_radar.update_layout(\n",
    "            height=450,\n",
    "            polar=dict(radialaxis=dict(visible=True, range=[0, 1])),\n",
    "            font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "            title_font_size=16\n",
    "        )\n",
    "        st.plotly_chart(fig_radar, use_container_width=True)\n",
    "\n",
    "    # Additional trend analysis\n",
    "    st.subheader(\"üìà Comparative Trend Analysis\")\n",
    "    trend_col1, trend_col2 = st.columns(2)\n",
    "    \n",
    "    with trend_col1:\n",
    "        # Year-over-year comparison\n",
    "        if \"year\" in df_filtered.columns and len(df_filtered[\"year\"].unique()) > 1:\n",
    "            yearly_comparison = df_filtered.groupby([\"year\", \"season\"])[selected_metric].mean().reset_index()\n",
    "            fig_yearly = px.line(\n",
    "                yearly_comparison,\n",
    "                x=\"season\",\n",
    "                y=selected_metric,\n",
    "                color=\"year\",\n",
    "                markers=True,\n",
    "                title=f\"Year-over-Year Seasonal Comparison: {selected_metric_label}\",\n",
    "                labels={selected_metric: selected_metric_label, \"season\": \"Season\", \"year\": \"Year\"}\n",
    "            )\n",
    "            fig_yearly.update_layout(\n",
    "                height=400,\n",
    "                font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "                title_font_size=14\n",
    "            )\n",
    "            st.plotly_chart(fig_yearly, use_container_width=True)\n",
    "    \n",
    "    with trend_col2:\n",
    "        # Location comparison\n",
    "        top_locations = df_filtered.groupby(\"location_name\")[selected_metric].mean().nlargest(5).index\n",
    "        location_trends = df_filtered[df_filtered[\"location_name\"].isin(top_locations)]\n",
    "        \n",
    "        if agg_type == \"Monthly\":\n",
    "            loc_trend_df = location_trends.groupby([\"location_name\", \"month_name\", \"month_num\"])[selected_metric].mean().reset_index().sort_values(\"month_num\")\n",
    "            x_loc_col = \"month_name\"\n",
    "        else:\n",
    "            loc_trend_df = location_trends.groupby([\"location_name\", \"date\"])[selected_metric].mean().reset_index()\n",
    "            x_loc_col = \"date\"\n",
    "        \n",
    "        fig_loc_trend = px.line(\n",
    "            loc_trend_df,\n",
    "            x=x_loc_col,\n",
    "            y=selected_metric,\n",
    "            color=\"location_name\",\n",
    "            title=f\"Top 5 Locations Trend: {selected_metric_label}\",\n",
    "            labels={selected_metric: selected_metric_label}\n",
    "        )\n",
    "        fig_loc_trend.update_layout(\n",
    "            height=400,\n",
    "            font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "            title_font_size=14,\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
    "        )\n",
    "        st.plotly_chart(fig_loc_trend, use_container_width=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Page 4: Extreme Events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- PAGE 4: EXTREME EVENTS -------------------------\n",
    "if nav_selection == \"Extreme Events\":\n",
    "    st.title(\"‚ö° Extreme Weather Events\")\n",
    "    st.markdown(\"Identify and analyze extreme weather patterns and anomalies\")\n",
    "\n",
    "    st.sidebar.markdown(\"### ‚öôÔ∏è Extreme Thresholds\")\n",
    "    threshold_method = st.sidebar.radio(\n",
    "        \"Threshold Method\",\n",
    "        [\"Manual Input\", \"Percentile-Based\"],\n",
    "        key=\"thresh_method\"\n",
    "    )\n",
    "    \n",
    "    if threshold_method == \"Manual Input\":\n",
    "        temp_thresh = st.sidebar.number_input(\"Extreme Temp (> X ¬∞C)\", value=35.0, min_value=0.0, step=0.5, key=\"temp_man\")\n",
    "        wind_thresh = st.sidebar.number_input(\"Extreme Wind (> X kph)\", value=40.0, min_value=0.0, step=1.0, key=\"wind_man\")\n",
    "        precip_thresh = st.sidebar.number_input(\"Extreme Precip (> X mm)\", value=20.0, min_value=0.0, step=1.0, key=\"precip_man\")\n",
    "    else:\n",
    "        percentile_val = st.sidebar.slider(\"Percentile Threshold\", min_value=90, max_value=99, value=95, step=1, key=\"percentile\")\n",
    "        temp_thresh = df_filtered[\"temperature_celsius\"].quantile(percentile_val / 100)\n",
    "        wind_thresh = df_filtered[\"wind_kph\"].quantile(percentile_val / 100)\n",
    "        precip_thresh = df_filtered[\"precip_mm\"].quantile(percentile_val / 100)\n",
    "        st.sidebar.info(f\"**Auto-calculated:**\\n- Temp: {temp_thresh:.1f}¬∞C\\n- Wind: {wind_thresh:.1f} kph\\n- Precip: {precip_thresh:.1f} mm\")\n",
    "\n",
    "    # Extreme event summary cards\n",
    "    extremes_heat = df_filtered[df_filtered[\"temperature_celsius\"] > temp_thresh]\n",
    "    extremes_wind = df_filtered[df_filtered[\"wind_kph\"] > wind_thresh]\n",
    "    extremes_precip = df_filtered[df_filtered[\"precip_mm\"] > precip_thresh]\n",
    "    \n",
    "    ex_col1, ex_col2, ex_col3, ex_col4 = st.columns(4)\n",
    "    ex_col1.metric(\"üî• Heat Events\", len(extremes_heat), delta=f\"{len(extremes_heat)/len(df_filtered)*100:.1f}%\")\n",
    "    ex_col2.metric(\"üí® Wind Events\", len(extremes_wind), delta=f\"{len(extremes_wind)/len(df_filtered)*100:.1f}%\")\n",
    "    ex_col3.metric(\"üåßÔ∏è Precip Events\", len(extremes_precip), delta=f\"{len(extremes_precip)/len(df_filtered)*100:.1f}%\")\n",
    "    ex_col4.metric(\"üìä Total Extremes\", len(extremes_heat) + len(extremes_wind) + len(extremes_precip))\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Hall of Extremes with enhanced display\n",
    "    st.subheader(\"üèÜ Hall of Extremes\")\n",
    "    col_ex1, col_ex2, col_ex3, col_ex4 = st.columns(4)\n",
    "\n",
    "    with col_ex1:\n",
    "        st.markdown(\"**üî• Hottest Days**\")\n",
    "        hottest = df_filtered.nlargest(5, \"temperature_celsius\")[[\"date\", \"location_name\", \"country\", \"temperature_celsius\"]].copy()\n",
    "        hottest[\"temperature_celsius\"] = hottest[\"temperature_celsius\"].round(1)\n",
    "        st.dataframe(\n",
    "            hottest.style.background_gradient(cmap=\"Reds\", subset=[\"temperature_celsius\"]),\n",
    "            hide_index=True,\n",
    "            use_container_width=True\n",
    "        )\n",
    "\n",
    "    with col_ex2:\n",
    "        st.markdown(\"**‚ùÑÔ∏è Coldest Days**\")\n",
    "        coldest = df_filtered.nsmallest(5, \"temperature_celsius\")[[\"date\", \"location_name\", \"country\", \"temperature_celsius\"]].copy()\n",
    "        coldest[\"temperature_celsius\"] = coldest[\"temperature_celsius\"].round(1)\n",
    "        st.dataframe(\n",
    "            coldest.style.background_gradient(cmap=\"Blues\", subset=[\"temperature_celsius\"]),\n",
    "            hide_index=True,\n",
    "            use_container_width=True\n",
    "        )\n",
    "\n",
    "    with col_ex3:\n",
    "        st.markdown(\"**üí® Windiest Days**\")\n",
    "        windiest = df_filtered.nlargest(5, \"wind_kph\")[[\"date\", \"location_name\", \"country\", \"wind_kph\"]].copy()\n",
    "        windiest[\"wind_kph\"] = windiest[\"wind_kph\"].round(1)\n",
    "        st.dataframe(\n",
    "            windiest.style.background_gradient(cmap=\"Oranges\", subset=[\"wind_kph\"]),\n",
    "            hide_index=True,\n",
    "            use_container_width=True\n",
    "        )\n",
    "    \n",
    "    with col_ex4:\n",
    "        st.markdown(\"**üåßÔ∏è Wettest Days**\")\n",
    "        wettest = df_filtered.nlargest(5, \"precip_mm\")[[\"date\", \"location_name\", \"country\", \"precip_mm\"]].copy()\n",
    "        wettest[\"precip_mm\"] = wettest[\"precip_mm\"].round(1)\n",
    "        st.dataframe(\n",
    "            wettest.style.background_gradient(cmap=\"Blues\", subset=[\"precip_mm\"]),\n",
    "            hide_index=True,\n",
    "            use_container_width=True\n",
    "        )\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Extreme Event Analysis\n",
    "    st.subheader(\"üìä Extreme Event Analysis\")\n",
    "    \n",
    "    extremes = df_filtered[\n",
    "        (df_filtered[\"temperature_celsius\"] > temp_thresh) |\n",
    "        (df_filtered[\"wind_kph\"] > wind_thresh) |\n",
    "        (df_filtered[\"precip_mm\"] > precip_thresh)\n",
    "    ].copy()\n",
    "\n",
    "    if not extremes.empty:\n",
    "        def tag_extreme(row):\n",
    "            tags = []\n",
    "            if row[\"temperature_celsius\"] > temp_thresh: tags.append(\"Heatwave\")\n",
    "            if row[\"wind_kph\"] > wind_thresh: tags.append(\"High Wind\")\n",
    "            if row[\"precip_mm\"] > precip_thresh: tags.append(\"Heavy Rain\")\n",
    "            return \", \".join(tags) if tags else \"None\"\n",
    "\n",
    "        extremes[\"Event Type\"] = extremes.apply(tag_extreme, axis=1)\n",
    "        extremes = extremes[extremes[\"Event Type\"] != \"None\"]\n",
    "        \n",
    "        if not extremes.empty:\n",
    "            # Event frequency visualization\n",
    "            event_counts = extremes[\"Event Type\"].str.split(\", \", expand=True).stack().value_counts().reset_index()\n",
    "            event_counts.columns = [\"Event Type\", \"Count\"]\n",
    "            \n",
    "            fig_freq = px.bar(\n",
    "                event_counts, \n",
    "                x=\"Event Type\", \n",
    "                y=\"Count\", \n",
    "                color=\"Event Type\",\n",
    "                title=\"Frequency of Extreme Events\",\n",
    "                color_discrete_sequence=[COLOR_SCHEME['warning'], COLOR_SCHEME['secondary'], COLOR_SCHEME['info']],\n",
    "                labels={\"Count\": \"Number of Events\", \"Event Type\": \"Event Type\"}\n",
    "            )\n",
    "            fig_freq.update_layout(\n",
    "                height=400,\n",
    "                showlegend=False,\n",
    "                font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "                title_font_size=16\n",
    "            )\n",
    "            fig_freq.update_traces(hovertemplate=\"<b>%{x}</b><br>Count: %{y}<extra></extra>\")\n",
    "            st.plotly_chart(fig_freq, use_container_width=True)\n",
    "\n",
    "            # Temporal distribution of extremes\n",
    "            st.subheader(\"üìÖ Temporal Distribution of Extreme Events\")\n",
    "            ext_col1, ext_col2 = st.columns(2)\n",
    "            \n",
    "            with ext_col1:\n",
    "                extremes[\"month\"] = extremes[\"date\"].dt.month_name()\n",
    "                monthly_extremes = extremes.groupby([\"month\", \"Event Type\"]).size().reset_index(name=\"Count\")\n",
    "                monthly_extremes[\"month_num\"] = monthly_extremes[\"month\"].map({\n",
    "                    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4,\n",
    "                    \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8,\n",
    "                    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n",
    "                })\n",
    "                monthly_extremes = monthly_extremes.sort_values(\"month_num\")\n",
    "                \n",
    "                fig_monthly = px.bar(\n",
    "                    monthly_extremes,\n",
    "                    x=\"month\",\n",
    "                    y=\"Count\",\n",
    "                    color=\"Event Type\",\n",
    "                    title=\"Extreme Events by Month\",\n",
    "                    labels={\"Count\": \"Number of Events\", \"month\": \"Month\"},\n",
    "                    color_discrete_sequence=[COLOR_SCHEME['warning'], COLOR_SCHEME['secondary'], COLOR_SCHEME['info']]\n",
    "                )\n",
    "                fig_monthly.update_layout(\n",
    "                    height=400,\n",
    "                    font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "                    title_font_size=14,\n",
    "                    xaxis={'categoryorder': 'array', 'categoryarray': monthly_extremes[\"month\"].unique()}\n",
    "                )\n",
    "                st.plotly_chart(fig_monthly, use_container_width=True)\n",
    "            \n",
    "            with ext_col2:\n",
    "                seasonal_extremes = extremes.groupby([\"season\", \"Event Type\"]).size().reset_index(name=\"Count\")\n",
    "                fig_seasonal = px.bar(\n",
    "                    seasonal_extremes,\n",
    "                    x=\"season\",\n",
    "                    y=\"Count\",\n",
    "                    color=\"Event Type\",\n",
    "                    title=\"Extreme Events by Season\",\n",
    "                    labels={\"Count\": \"Number of Events\", \"season\": \"Season\"},\n",
    "                    color_discrete_sequence=[COLOR_SCHEME['warning'], COLOR_SCHEME['secondary'], COLOR_SCHEME['info']]\n",
    "                )\n",
    "                fig_seasonal.update_layout(\n",
    "                    height=400,\n",
    "                    font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "                    title_font_size=14\n",
    "                )\n",
    "                st.plotly_chart(fig_seasonal, use_container_width=True)\n",
    "\n",
    "            # Regional breakdown\n",
    "            st.subheader(\"üåç Regional Breakdown of Extremes\")\n",
    "            regional_ext = extremes.groupby([\"country\", \"Event Type\"]).size().reset_index(name=\"Count\")\n",
    "            \n",
    "            fig_reg_scat = px.scatter(\n",
    "                regional_ext, \n",
    "                x=\"country\", \n",
    "                y=\"Event Type\", \n",
    "                size=\"Count\", \n",
    "                color=\"Count\",\n",
    "                title=\"Regional Extreme Event Intensity\",\n",
    "                color_continuous_scale=\"Reds\",\n",
    "                labels={\"Count\": \"Number of Events\", \"country\": \"Country\", \"Event Type\": \"Event Type\"},\n",
    "                hover_data=[\"Count\"]\n",
    "            )\n",
    "            fig_reg_scat.update_layout(\n",
    "                height=500,\n",
    "                font=dict(family=\"Arial, sans-serif\", size=11),\n",
    "                title_font_size=16\n",
    "            )\n",
    "            st.plotly_chart(fig_reg_scat, use_container_width=True)\n",
    "            \n",
    "            # Location-level heatmap\n",
    "            st.subheader(\"üìç Location-Level Extreme Event Heatmap\")\n",
    "            location_ext = extremes.groupby([\"location_name\", \"Event Type\"]).size().reset_index(name=\"Count\")\n",
    "            location_pivot = location_ext.pivot(index=\"location_name\", columns=\"Event Type\", values=\"Count\").fillna(0)\n",
    "            \n",
    "            if not location_pivot.empty:\n",
    "                fig_heatmap = px.imshow(\n",
    "                    location_pivot.head(20),  # Top 20 locations\n",
    "                    labels=dict(x=\"Event Type\", y=\"Location\", color=\"Count\"),\n",
    "                    title=\"Top 20 Locations - Extreme Event Frequency\",\n",
    "                    color_continuous_scale=\"Reds\",\n",
    "                    aspect=\"auto\"\n",
    "                )\n",
    "                fig_heatmap.update_layout(\n",
    "                    height=600,\n",
    "                    font=dict(family=\"Arial, sans-serif\", size=10),\n",
    "                    title_font_size=16\n",
    "                )\n",
    "                st.plotly_chart(fig_heatmap, use_container_width=True)\n",
    "        else:\n",
    "            st.info(\"No extreme events found with the current thresholds.\")\n",
    "    else:\n",
    "        st.info(\"No extreme events found with the current thresholds. Try adjusting the threshold values in the sidebar.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Page 5: Help & User Guide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- PAGE 5: HELP & USER GUIDE -------------------------\n",
    "if nav_selection == \"Help & User Guide\":\n",
    "    st.title(\"üìò User Guide & Documentation\")\n",
    "    st.markdown(\"Comprehensive guide to using the ClimateScope Interactive Dashboard\")\n",
    "    \n",
    "    tab1, tab2, tab3, tab4 = st.tabs([\"Getting Started\", \"Features\", \"Visualizations\", \"Tips & Tricks\"])\n",
    "    \n",
    "    with tab1:\n",
    "        st.header(\"üöÄ Getting Started\")\n",
    "        st.markdown(\"\"\"\n",
    "        ### Welcome to ClimateScope!\n",
    "        \n",
    "        ClimateScope is an interactive dashboard for analyzing climate and weather data. Follow these steps to get started:\n",
    "        \n",
    "        #### 1. **Navigation**\n",
    "        - Use the sidebar radio buttons to switch between different analysis pages:\n",
    "          - **Executive Dashboard**: High-level overview and KPIs\n",
    "          - **Statistical Analysis**: Detailed statistical insights and correlations\n",
    "          - **Climate Trends**: Temporal patterns and seasonal analysis\n",
    "          - **Extreme Events**: Identification and analysis of extreme weather\n",
    "          - **Help & User Guide**: This page\n",
    "        \n",
    "        #### 2. **Global Filters** (Sidebar)\n",
    "        - **Country Selection**: Toggle \"Select All Countries\" or choose specific countries\n",
    "        - **Location Selection**: Filter by specific locations/cities\n",
    "        - **Date Range**: Select the time period for analysis\n",
    "        - **Primary Metric**: Choose the main variable to analyze (Temperature, Precipitation, etc.)\n",
    "        \n",
    "        #### 3. **Advanced Controls**\n",
    "        - **Visualization Settings**: Adjust moving averages, trend lines, and confidence bands\n",
    "        - **Threshold Settings**: Configure percentile thresholds for anomaly detection\n",
    "        \n",
    "        #### 4. **Interacting with Charts**\n",
    "        - **Zoom**: Click and drag to zoom into specific areas\n",
    "        - **Pan**: Click and drag to move around the chart\n",
    "        - **Reset**: Double-click to reset the view\n",
    "        - **Hover**: Hover over data points to see detailed information\n",
    "        - **Download**: Use the camera icon to download charts as PNG images\n",
    "        \"\"\")\n",
    "    \n",
    "    with tab2:\n",
    "        st.header(\"‚ú® Key Features\")\n",
    "        \n",
    "        col_feat1, col_feat2 = st.columns(2)\n",
    "        \n",
    "        with col_feat1:\n",
    "            st.subheader(\"üìä Interactive Visualizations\")\n",
    "            st.markdown(\"\"\"\n",
    "            - **Interactive Maps**: Choropleth maps showing global distribution\n",
    "            - **Dynamic Charts**: All charts update based on your filters\n",
    "            - **Multiple Chart Types**: Line, bar, scatter, box, violin, radar, and more\n",
    "            - **Real-time Updates**: Changes reflect immediately when filters are adjusted\n",
    "            \"\"\")\n",
    "            \n",
    "            st.subheader(\"üîç Advanced Analytics\")\n",
    "            st.markdown(\"\"\"\n",
    "            - **Moving Averages**: Configurable time windows (1-30 days)\n",
    "            - **Anomaly Detection**: Automatic identification of outliers\n",
    "            - **Correlation Analysis**: Heatmaps showing variable relationships\n",
    "            - **Trend Analysis**: Multiple aggregation levels (Daily, Weekly, Monthly, Seasonal, Yearly)\n",
    "            \"\"\")\n",
    "        \n",
    "        with col_feat2:\n",
    "            st.subheader(\"üåç Geographic Analysis\")\n",
    "            st.markdown(\"\"\"\n",
    "            - **Country-level Filtering**: Analyze specific regions\n",
    "            - **Location-level Details**: Drill down to city/location level\n",
    "            - **Regional Comparisons**: Compare patterns across different areas\n",
    "            - **Global Distribution Maps**: Visualize spatial patterns\n",
    "            \"\"\")\n",
    "            \n",
    "            st.subheader(\"‚ö° Extreme Event Detection\")\n",
    "            st.markdown(\"\"\"\n",
    "            - **Customizable Thresholds**: Manual or percentile-based\n",
    "            - **Event Classification**: Automatic tagging of heatwaves, high winds, heavy rain\n",
    "            - **Temporal Analysis**: Monthly and seasonal breakdowns\n",
    "            - **Regional Mapping**: Identify hotspots for extreme events\n",
    "            \"\"\")\n",
    "    \n",
    "    with tab3:\n",
    "        st.header(\"üìà Visualization Guide\")\n",
    "        \n",
    "        st.subheader(\"Executive Dashboard\")\n",
    "        st.markdown(\"\"\"\n",
    "        - **KPI Cards**: Key performance indicators with delta indicators\n",
    "        - **Global Map**: Choropleth map showing average values by country\n",
    "        - **Top Locations**: Bar chart of locations with highest values\n",
    "        - **Trend Line**: Time series with optional moving averages and confidence bands\n",
    "        - **Insights Panel**: Automated findings and statistical highlights\n",
    "        \"\"\")\n",
    "        \n",
    "        st.subheader(\"Statistical Analysis\")\n",
    "        st.markdown(\"\"\"\n",
    "        - **Descriptive Statistics**: Comprehensive statistical summary table\n",
    "        - **Correlation Matrix**: Heatmap showing relationships between variables\n",
    "        - **Scatter Plots**: Interactive scatter plots with customizable axes and coloring\n",
    "        - **Distribution Charts**: Histograms and density plots\n",
    "        - **Trend Lines**: Optional regression lines on scatter plots\n",
    "        \"\"\")\n",
    "        \n",
    "        st.subheader(\"Climate Trends\")\n",
    "        st.markdown(\"\"\"\n",
    "        - **Time Aggregation**: Daily, Weekly, Monthly, Seasonal, or Yearly views\n",
    "        - **Multi-metric Comparison**: Compare multiple variables simultaneously\n",
    "        - **Seasonal Analysis**: Box plots and violin plots by season\n",
    "        - **Radar Charts**: Normalized seasonal climate profiles\n",
    "        - **Year-over-Year**: Compare trends across different years\n",
    "        - **Location Trends**: Track top locations over time\n",
    "        \"\"\")\n",
    "        \n",
    "        st.subheader(\"Extreme Events\")\n",
    "        st.markdown(\"\"\"\n",
    "        - **Hall of Extremes**: Tables showing hottest, coldest, windiest, wettest days\n",
    "        - **Event Frequency**: Bar charts of extreme event counts\n",
    "        - **Temporal Distribution**: Monthly and seasonal breakdowns\n",
    "        - **Regional Analysis**: Scatter plots and heatmaps by country/location\n",
    "        - **Threshold Configuration**: Manual or percentile-based thresholds\n",
    "        \"\"\")\n",
    "    \n",
    "    with tab4:\n",
    "        st.header(\"üí° Tips & Best Practices\")\n",
    "        \n",
    "        st.subheader(\"Optimizing Your Analysis\")\n",
    "        st.markdown(\"\"\"\n",
    "        1. **Start Broad, Then Narrow**: Begin with all countries/locations, then filter down\n",
    "        2. **Use Date Ranges Wisely**: Longer periods show trends, shorter periods show details\n",
    "        3. **Compare Metrics**: Use the multi-metric feature to understand relationships\n",
    "        4. **Check Anomalies**: Enable anomaly detection to find outliers automatically\n",
    "        5. **Explore Correlations**: Use the correlation matrix to identify related variables\n",
    "        \"\"\")\n",
    "        \n",
    "        st.subheader(\"Interpreting Results\")\n",
    "        st.markdown(\"\"\"\n",
    "        - **Moving Averages**: Smooth out daily fluctuations to see underlying trends\n",
    "        - **Confidence Bands**: Show the range of expected values (95% confidence interval)\n",
    "        - **Percentile Thresholds**: Use for anomaly detection based on historical data\n",
    "        - **Seasonal Patterns**: Look for consistent patterns across seasons\n",
    "        - **Regional Differences**: Compare countries to identify climate variations\n",
    "        \"\"\")\n",
    "        \n",
    "        st.subheader(\"Performance Tips\")\n",
    "        st.markdown(\"\"\"\n",
    "        - **Filter Early**: Apply filters before loading large datasets\n",
    "        - **Limit Locations**: When analyzing many locations, consider filtering to top performers\n",
    "        - **Use Aggregations**: Monthly/Seasonal views are faster than daily for large datasets\n",
    "        - **Disable Optional Features**: Turn off confidence bands and trend lines if not needed\n",
    "        \"\"\")\n",
    "        \n",
    "        st.subheader(\"Troubleshooting\")\n",
    "        st.markdown(\"\"\"\n",
    "        - **No Data**: Check that your filters aren't too restrictive\n",
    "        - **Charts Not Loading**: Ensure the data file exists and is properly formatted\n",
    "        - **Missing Values**: Some metrics may have missing data - check the data completeness metric\n",
    "        - **Slow Performance**: Reduce date range or number of locations selected\n",
    "        \"\"\")\n",
    "    \n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"### üìû Need More Help?\")\n",
    "    st.info(\"\"\"\n",
    "    For additional support or to report issues, please refer to the project documentation or contact the development team.\n",
    "    All visualizations are powered by Plotly and are fully interactive. Explore the data and discover insights!\n",
    "    \"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
